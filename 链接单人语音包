from datetime import datetime
import os
import glob 
import base64
import hashlib
import hmac
import requests
import time
import uuid
from urllib import parse
import pandas as pd
import http.client
import json
from pydub import AudioSegment
from pydub.silence import split_on_silence
import threading
import you_get
import numpy as np
import subprocess
import zipfile
import shutil
import multiprocessing
import requests
import re
import json
from datetime import datetime
from lxml import etree
from concurrent.futures import ThreadPoolExecutor

'''多人多链接
   将压缩包移动到指定文件夹，如果之前文件夹有重名，处理方式
   b站如果是一个列表应该怎么下载，或者备注
   多参数问题
'''
'''
全局变量声明
'''
default_silence=630
default_thresh=-30

#改后缀的地方
hzcontent='（素材分享群：123593137，获取更多素材）.mp3'
       

rootpath='C:\\Users\\Administrator\\Desktop\\test2\\'
to_split_path=rootpath+'to_split_audio\\'
#dataurl=pd.read_csv(txtpath,header=None,sep='\n')
       
#if not os.path.exists(to_split_path):os.mkdir(to_split_path)
chunkspath=rootpath+'chunks\\'
wavpath=rootpath+'转wav\\'
logpath=rootpath+'日志\\'
txtpath='C:\\Users\\Administrator\\Desktop\\下载链接.txt'
dataurl=pd.read_csv(txtpath,header=None,sep='\n')
       
data_total=pd.DataFrame(data=None,columns=['编号','语音内容'])

ziptofile='E:\\test2\\新版语音包纯净版本\\'
ziptofile_hz='E:\\test2\\新版语音包带后缀版本\\'


#删除之前留下的文件
if  os.path.exists(chunkspath):
    shutil.rmtree(chunkspath)
if not os.path.exists(chunkspath):os.mkdir(chunkspath)

if  os.path.exists(to_split_path):
    shutil.rmtree(to_split_path)
if not os.path.exists(to_split_path):os.mkdir(to_split_path)

if os.path.exists(wavpath):
    shutil.rmtree(wavpath)
if not os.path.exists(wavpath):os.mkdir(wavpath)
    

def single():

    datam=dataurl
    namelist=[]
    urllist=[]
    silencelist=[]
    threshlist=[]
    for i in range(0,len(datam),1):
        if datam.loc[i,0][0:4]!='http':
            name=datam.loc[i,0].split()
            print(name)
            namelist.append(name[0])
            urllist.append(i)
            if len(name)>1:
                silencelist.append(int(name[1]))
                threshlist.append(int(name[2]))
            else:
                silencelist.append(default_silence)
                threshlist.append(default_thresh)
    return namelist,urllist,silencelist,threshlist
    
    



def dataframe_trans(namelist,urllist,dataurl):
#构建新的dataframe  格式的转换
    data_new_url=pd.DataFrame(data=None,columns=['人物名字','url链接'])
    for i in range(0,len(namelist),1):
         if i==(len(namelist)-1):
             data_url=dataurl[urllist[i]+1:]
             data_url.rename(columns={0:'url链接'},inplace=True)
             
             data_url.loc[:,'人物名字']=namelist[i]
             data_new_url=pd.concat([data_new_url,data_url])
             
         else:
             
             data_url=dataurl[urllist[i]+1:urllist[i+1]]
             data_url.rename(columns={0:'url链接'},inplace=True)
             
             data_url.loc[:,'人物名字']=namelist[i]
             data_new_url=pd.concat([data_new_url,data_url])


    return data_new_url


def file_make(namelist):
#创建文件夹 chunks  to_split_audio 转wav
    if len(namelist)>0:
        for i in namelist:
            to_split_file=to_split_path+i+'\\'   
            chunks_file=chunkspath+i+'\\'
            pcm_file=wavpath+i+'\\'
            
            if not os.path.exists(to_split_file):os.mkdir(to_split_file)
            #if not os.path.exists(chunks_file):os.mkdir(chunks_file)
           # if not os.path.exists(pcm_file):os.mkdir(pcm_file)

def data_new_url():


    if  os.path.exists(chunkspath):
        shutil.rmtree(chunkspath)
    if not os.path.exists(chunkspath):os.mkdir(chunkspath)

    if  os.path.exists(to_split_path):
        shutil.rmtree(to_split_path)
    if not os.path.exists(to_split_path):os.mkdir(to_split_path)

    if os.path.exists(wavpath):
        shutil.rmtree(wavpath)
    if not os.path.exists(wavpath):os.mkdir(wavpath)
    
    dataurl=pd.read_csv(txtpath,header=None,sep='\n')
  
       # remove_file(to_split_path,type='all')
    namelist,urllist,silencelist,threshlist=single()
    data_new_url=dataframe_trans(namelist,urllist,dataurl)
    data_new_url=data_new_url.reset_index(drop=True)
    data_new_url.sort_values('人物名字',ascending=True,inplace=True)
    data_new_url['下载类型']=data_new_url['url链接'].map(lambda x:x.split(' ')[-1])
   
    data_new_url['url链接']=data_new_url['url链接'].map(lambda x:x.split(' ')[0])
    #data_new_url['下载类型']=data_new_url['url链接'].map(lambda x:x.split(' ')[-1])
   
   
    file_make(namelist)
    return data_new_url



"""
你可以组合下载器返回的协程对象，利用gather并发执行他们，他们执行的并发度收到下载器对象的严格约束，因此不会对服务器造成意想不到的负担。
"""
import asyncio
from bilix import DownloaderBilibili

corlist=[]
data_new_url=data_new_url()

async def main():
   # d = DownloaderBilibili(videos_dir=to_split_path,video_concurrency=5, part_concurrency=10)
    for i in range(0,len(data_new_url),1):
        if data_new_url.loc[i,'下载类型']=='all':
            d = DownloaderBilibili(videos_dir=to_split_path+data_new_url.loc[i,'人物名字']+'\\',video_concurrency=5, part_concurrency=10)

            cor= d.get_series(data_new_url.loc[i,'url链接'],only_audio=True,hierarchy=False)
            corlist.append(cor)
        elif  data_new_url.loc[i,'下载类型'][0:3]=='num':
            d = DownloaderBilibili(videos_dir=to_split_path+data_new_url.loc[i,'人物名字']+'\\',video_concurrency=5, part_concurrency=10)
            num=data_new_url.loc[i,'下载类型'].split('=')[1]
            cor= d.get_up_videos(url_or_mid=data_new_url.loc[i,'url链接'],num=int(num),only_audio=True,hierarchy=False)
            corlist.append(cor)
        else:
            d = DownloaderBilibili(videos_dir=to_split_path+data_new_url.loc[i,'人物名字']+'\\',video_concurrency=5, part_concurrency=10)
            cor= d.get_video(data_new_url.loc[i,'url链接'],only_audio=True)
            corlist.append(cor)

        

    await asyncio.gather(*corlist)
    #await d.aclose()


if __name__ == '__main__':
    time_d1=datetime.now()

    # asyncio.run(main())
    await main()

    time_d2=datetime.now()
    print('下载花费时间',time_d2-time_d1)

    #await main()
    #main()
